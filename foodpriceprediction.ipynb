{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94018cd0-39f1-4f3d-9618-4134a9623bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date      admin1      admin2            market   latitude  longitude  \\\n",
      "0       #date  #adm1+name  #adm2+name  #loc+market+name   #geo+lat   #geo+lon   \n",
      "1  1994-01-15       Delhi       Delhi             Delhi  28.666667  77.216667   \n",
      "2  1994-01-15       Delhi       Delhi             Delhi  28.666667  77.216667   \n",
      "3  1994-01-15       Delhi       Delhi             Delhi  28.666667  77.216667   \n",
      "4  1994-01-15       Delhi       Delhi             Delhi  28.666667  77.216667   \n",
      "\n",
      "             category      commodity        unit         priceflag  \\\n",
      "0          #item+type     #item+name  #item+unit  #item+price+flag   \n",
      "1  cereals and tubers           Rice          KG            actual   \n",
      "2  cereals and tubers          Wheat          KG            actual   \n",
      "3  miscellaneous food          Sugar          KG            actual   \n",
      "4        oil and fats  Oil (mustard)          KG            actual   \n",
      "\n",
      "          pricetype   currency   price    usdprice  \n",
      "0  #item+price+type  #currency  #value  #value+usd  \n",
      "1            Retail        INR     8.0      0.2545  \n",
      "2            Retail        INR     5.0       0.159  \n",
      "3            Retail        INR    13.5      0.4294  \n",
      "4            Retail        INR    31.0       0.986  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cp756\\AppData\\Local\\Temp\\ipykernel_2044\\50839080.py:4: DtypeWarning: Columns (4,5,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r\"D:\\Python\\foodprice\\wfp_food_prices_ind.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load historical food price data\n",
    "df = pd.read_csv(r\"D:\\Python\\foodprice\\wfp_food_prices_ind.csv\")\n",
    "\n",
    "# Explore the data\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4234d876-a886-4bac-bf3f-9c9b2445ad80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 172018 entries, 0 to 172017\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   date       172018 non-null  object\n",
      " 1   admin1     171229 non-null  object\n",
      " 2   admin2     171229 non-null  object\n",
      " 3   market     172018 non-null  object\n",
      " 4   latitude   171229 non-null  object\n",
      " 5   longitude  171229 non-null  object\n",
      " 6   category   172018 non-null  object\n",
      " 7   commodity  172018 non-null  object\n",
      " 8   unit       172018 non-null  object\n",
      " 9   priceflag  172018 non-null  object\n",
      " 10  pricetype  172018 non-null  object\n",
      " 11  currency   172018 non-null  object\n",
      " 12  price      172018 non-null  object\n",
      " 13  usdprice   172018 non-null  object\n",
      "dtypes: object(14)\n",
      "memory usage: 18.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1d3992a-f3f7-46ed-aa4b-695e2b52b60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date           0\n",
       "admin1       789\n",
       "admin2       789\n",
       "market         0\n",
       "latitude     789\n",
       "longitude    789\n",
       "category       0\n",
       "commodity      0\n",
       "unit           0\n",
       "priceflag      0\n",
       "pricetype      0\n",
       "currency       0\n",
       "price          0\n",
       "usdprice       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd934047-391b-4235-aa66-8f4a124e6385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8795f531-0408-41f1-87a3-9eb9d34b4b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>admin1</th>\n",
       "      <th>admin2</th>\n",
       "      <th>market</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>category</th>\n",
       "      <th>commodity</th>\n",
       "      <th>unit</th>\n",
       "      <th>priceflag</th>\n",
       "      <th>pricetype</th>\n",
       "      <th>currency</th>\n",
       "      <th>price</th>\n",
       "      <th>usdprice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>172018</td>\n",
       "      <td>171229</td>\n",
       "      <td>171229</td>\n",
       "      <td>172018</td>\n",
       "      <td>171229</td>\n",
       "      <td>171229</td>\n",
       "      <td>172018</td>\n",
       "      <td>172018</td>\n",
       "      <td>172018</td>\n",
       "      <td>172018</td>\n",
       "      <td>172018</td>\n",
       "      <td>172018</td>\n",
       "      <td>172018.0</td>\n",
       "      <td>172018.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>344</td>\n",
       "      <td>32</td>\n",
       "      <td>159</td>\n",
       "      <td>166</td>\n",
       "      <td>220</td>\n",
       "      <td>216</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>28483.0</td>\n",
       "      <td>43311.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2022-05-15</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Mumbai city</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>18.975</td>\n",
       "      <td>72.825833</td>\n",
       "      <td>oil and fats</td>\n",
       "      <td>Rice</td>\n",
       "      <td>KG</td>\n",
       "      <td>actual</td>\n",
       "      <td>Retail</td>\n",
       "      <td>INR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.2667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3290</td>\n",
       "      <td>13173</td>\n",
       "      <td>4364</td>\n",
       "      <td>4364</td>\n",
       "      <td>2920</td>\n",
       "      <td>2920</td>\n",
       "      <td>41865</td>\n",
       "      <td>12430</td>\n",
       "      <td>160694</td>\n",
       "      <td>172017</td>\n",
       "      <td>169740</td>\n",
       "      <td>172017</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>348.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date         admin1       admin2  market latitude  longitude  \\\n",
       "count       172018         171229       171229  172018   171229     171229   \n",
       "unique         344             32          159     166      220        216   \n",
       "top     2022-05-15  Uttar Pradesh  Mumbai city  Mumbai   18.975  72.825833   \n",
       "freq          3290          13173         4364    4364     2920       2920   \n",
       "\n",
       "            category commodity    unit priceflag pricetype currency     price  \\\n",
       "count         172018    172018  172018    172018    172018   172018  172018.0   \n",
       "unique             7        24       4         2         3        2   28483.0   \n",
       "top     oil and fats      Rice      KG    actual    Retail      INR      20.0   \n",
       "freq           41865     12430  160694    172017    169740   172017    1612.0   \n",
       "\n",
       "           usdprice  \n",
       "count   172018.0000  \n",
       "unique   43311.0000  \n",
       "top          0.2667  \n",
       "freq       348.0000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7ccb3b5-57e9-4752-8cee-ee792dc017ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(10, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3891c4e0-d013-437e-96be-efe16df26afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56a9fd91-def1-45c1-a56d-6ed26534f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# File paths\n",
    "train_path = r\"D:\\Python\\foodprice\\wfp_food_prices_ind.csv\"\n",
    "test_path = r\"D:\\Python\\foodprice\\wfp_food_prices_ind.csv\"\n",
    "desc_path = r\"D:\\Python\\foodprice\\wfp_food_prices_ind.csv\"\n",
    "\n",
    "# Check if files exist\n",
    "if not all(map(os.path.exists, [train_path, test_path, desc_path])):\n",
    "    raise FileNotFoundError(\"One or more files were not found. Please check the file paths.\")\n",
    "\n",
    "try:\n",
    "    with open(train_path, 'r', encoding='utf-8') as train_file:\n",
    "        train_reader = csv.reader(train_file)\n",
    "        train_data = [row for row in train_reader]\n",
    "\n",
    "    with open(test_path, 'r', encoding='utf-8') as test_file:\n",
    "        test_reader = csv.reader(test_file)\n",
    "        test_data = [row for row in test_reader]\n",
    "\n",
    "    with open(desc_path, 'r', encoding='utf-8') as desc_file:\n",
    "        descriptions = desc_file.readlines()\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found: {e}\")\n",
    "except IOError as e:\n",
    "    print(f\"IO error occurred: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbc962dc-b10d-46fe-8c6f-b14271204aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_descriptions = [item[3] for item in train_data] + [item[2] for item in test_data] + descriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3b2d812-3fa8-4a61-8570-24a78777c564",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [item[2] for item in train_data] + [None for _ in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d676cd4b-c8aa-43c8-bed8-f0b56536eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e287707a-e1a7-403f-b582-51ed1fe89a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(all_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2099c721-06a2-44f2-b41b-7bc1ec30e3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(all_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc7f00c3-bf9b-4a58-9ad4-76d616c38f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pading sequences to a fixed length\n",
    "max_sequence_length = 100 \n",
    "sequences = pad_sequences(sequences, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03fd142c-4781-41e7-9c51-0ffd1fe5fe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b1c3759-c550-4508-b931-3c5d93d8530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = sequences[:len(train_data)]\n",
    "test_sequences = sequences[len(train_data):len(train_data) + len(test_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "812ab60a-f228-47c5-9a14-07e2b2919175",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_sequences, encoded_labels[:len(train_data)], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7c06dfbf-ce1c-4604-9a68-7368963238ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cp756\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=128, input_length=max_sequence_length))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b665fe1-24cc-4111-a64e-b707ca84f448",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c2ac49c4-53cb-4de0-9019-56f4cd54fba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cp756\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m)      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m4297/4301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 62700.9180 - mae: 76.6995\n",
      "Epoch 1: val_loss did not improve from inf\n",
      "\u001b[1m4301/4301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - loss: 62696.9375 - mae: 76.6932 - val_loss: nan - val_mae: nan\n",
      "Epoch 2/50\n",
      "\u001b[1m4290/4301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56947.5742 - mae: 71.7449\n",
      "Epoch 2: val_loss did not improve from inf\n",
      "\u001b[1m4301/4301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 56946.8906 - mae: 71.7488 - val_loss: nan - val_mae: nan\n",
      "Epoch 3/50\n",
      "\u001b[1m4299/4301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56766.0312 - mae: 75.8396\n",
      "Epoch 3: val_loss did not improve from inf\n",
      "\u001b[1m4301/4301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 56765.8945 - mae: 75.8397 - val_loss: nan - val_mae: nan\n",
      "Epoch 3: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Best model saved at: wfp_food_prices_ind.keras\n"
     ]
    }
   ],
   "source": [
    "# Convert relevant columns to numeric\n",
    "numeric_columns = ['latitude', 'longitude', 'price', 'usdprice', 'category', 'commodity', 'unit','priceflag'] \n",
    "df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Drop non-numeric columns\n",
    "X = df.drop(columns=['price', 'usdprice', 'date', 'admin1', 'admin2', 'market', 'category', \n",
    "                     'commodity', 'unit', 'priceflag', 'pricetype', 'currency'])\n",
    "\n",
    "#features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# The target variable\n",
    "y = df['price'].values\n",
    "\n",
    "X_scaled = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#path to save the best model\n",
    "model_save_path = r'wfp_food_prices_ind.keras'\n",
    "\n",
    "#ModelCheckpoint callback\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=model_save_path,\n",
    "    monitor='val_loss',   \n",
    "    save_best_only=True,       \n",
    "    mode='min',            \n",
    "    verbose=1                 \n",
    ")\n",
    "\n",
    "# Create an EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',        \n",
    "    patience=3,              \n",
    "    verbose=1,                 \n",
    "    restore_best_weights=True  \n",
    ")\n",
    "\n",
    "# List of callbacks to be used during training\n",
    "callbacks_list = [checkpoint, early_stopping]\n",
    "\n",
    "# Model architecture\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(64, return_sequences=True, input_shape=(1, 6))),  \n",
    "    Dropout(0.5),                                                      \n",
    "    LSTM(32),                                                           \n",
    "    Dropout(0.5),                                                       \n",
    "    Dense(1, activation='linear')                                       \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_data=(X_val, y_val),       \n",
    "    epochs=50,                                       \n",
    "    batch_size=32,                                 \n",
    "    callbacks=callbacks_list                         \n",
    ")\n",
    "\n",
    "# After training, the best model is saved at 'Food_Price_Predictor.keras'\n",
    "print(f\"Best model saved at: {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5b5bbd30-0ea7-4ec4-bb4e-2127c6dda01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = r\"D:\\Python\\wfp_food_prices_ind.keras\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ffe15dfb-2c25-497e-8faf-52e433aa2511",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f1e12219-635d-4f2c-9066-efe20c008cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    }
   ],
   "source": [
    "model.save(model_save_path, save_format='keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f6517ab1-538b-49f4-b51e-9060201b13dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model(model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7ab9bf00-69a6-438c-b2b4-b18af8fe533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in HDF5 format\n",
    "model.save(r'D:\\Python\\archive\\Food_Price_Predictor.keras')\n",
    "\n",
    "# Load the model\n",
    "loaded_model = load_model(r'D:\\Python\\archive\\Food_Price_Predictor.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "556272a2-68a4-4755-9855-adf1437d4def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Python\\\\archive\\\\label_encoders.pkl']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_save_path = (r'D:\\Python\\archive\\scaler.pkl')\n",
    "joblib.dump(scaler, scaler_save_path)\n",
    "\n",
    "categorical_columns = ['category', 'commodity', 'unit', 'pricetype']\n",
    "\n",
    "label_encoder = {}\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col]) \n",
    "    label_encoder[col] = le  \n",
    "    \n",
    "encoders_save_path = (r'D:\\Python\\archive\\label_encoders.pkl')\n",
    "joblib.dump(label_encoder,encoders_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4ac98ad4-7811-433f-b751-41b971d71005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the label encoders, scaler, and model\n",
    "loaded_model = load_model(model_save_path)\n",
    "loaded_scaler = joblib.load(scaler_save_path)\n",
    "with open(encoders_save_path, 'rb') as f:\n",
    "    loaded_label_encoders = joblib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ddc8e4f4-4008-4da8-908b-9aa53716d313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'cereals and tubers' is a new category. Assigning unknown label (-1).\n",
      "Warning: 'Rice' is a new category. Assigning unknown label (-1).\n",
      "Warning: 'KG' is a new category. Assigning unknown label (-1).\n",
      "Warning: 'Retail' is a new category. Assigning unknown label (-1).\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621ms/step\n",
      "Predicted Price: 70.74281311035156\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model, scaler, and encoders\n",
    "loaded_model = load_model(model_save_path)\n",
    "loaded_scaler = joblib.load(scaler_save_path)\n",
    "\n",
    "\n",
    "with open(encoders_save_path, 'rb') as f:\n",
    "    loaded_label_encoders = joblib.load(f)\n",
    "\n",
    "# Define new data\n",
    "new_data = {\n",
    "    'latitude': 27.5706,\n",
    "    'longitude': 80.0982,\n",
    "    'category': 'cereals and tubers',\n",
    "    'commodity': 'Rice',\n",
    "    'unit': 'KG',\n",
    "    'pricetype': 'Retail'\n",
    "}\n",
    "\n",
    "# Encode categorical variables properly\n",
    "encoded_data = {}\n",
    "for column in ['category', 'commodity', 'unit', 'pricetype']:\n",
    "    if column in loaded_label_encoders:\n",
    "        le = loaded_label_encoders[column] \n",
    "        if new_data[column] in le.classes_:\n",
    "            encoded_data[column] = le.transform([new_data[column]])[0] \n",
    "        else:\n",
    "            print(f\"Warning: '{new_data[column]}' is a new category. Assigning unknown label (-1).\")\n",
    "            encoded_data[column] = -1  \n",
    "    else:\n",
    "        raise KeyError(f\"Error: Encoder for '{column}' not found!\")\n",
    "\n",
    "# Add numerical features\n",
    "encoded_data['latitude'] = new_data['latitude']\n",
    "encoded_data['longitude'] = new_data['longitude']\n",
    "\n",
    "# Convert to DataFrame (Ensure Correct Column Order)\n",
    "new_data_df = pd.DataFrame([encoded_data])\n",
    "\n",
    "# Make sure column names match the original training data\n",
    "expected_columns = loaded_scaler.feature_names_in_  # Get original feature names\n",
    "missing_cols = set(expected_columns) - set(new_data_df.columns)\n",
    "extra_cols = set(new_data_df.columns) - set(expected_columns)\n",
    "\n",
    "\n",
    "# Reorder columns to match the scaler's expected input\n",
    "new_data_df = new_data_df[expected_columns]\n",
    "\n",
    "# Scale the data\n",
    "new_data_scaled = loaded_scaler.transform(new_data_df)\n",
    "\n",
    "# Reshape input to be 3D [samples, timesteps, features]\n",
    "new_data_scaled = new_data_scaled.reshape((new_data_scaled.shape[0], 1, new_data_scaled.shape[1]))\n",
    "\n",
    "# Predict\n",
    "predicted_price = loaded_model.predict(new_data_scaled)\n",
    "\n",
    "print(f\"Predicted Price: {predicted_price[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "712c96aa-90a2-44e1-9a0f-57916ee5376e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model, details, and scaler saved to model_details.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load your trained model\n",
    "model_path = r'D:\\Python\\archive\\Food_Price_Predictor.keras'\n",
    "loaded_model = load_model(model_path)\n",
    "\n",
    "# Load your scaler\n",
    "scaler_path = r'D:\\Python\\archive\\scaler.save'\n",
    "loaded_scaler = joblib.load(scaler_path)\n",
    "\n",
    "# Create a dictionary with model details, including the model and scaler\n",
    "model_details = {\n",
    "    'model': loaded_model,  # Include the model in the dictionary\n",
    "    'scaler': loaded_scaler,\n",
    "    'description': 'LSTM model for food price prediction',\n",
    "    'input_shape': loaded_model.input_shape,\n",
    "}\n",
    "\n",
    "# Save the details to a .pkl file\n",
    "details_path =  r'D:\\Python\\archive\\model_details.pkl'\n",
    "with open(details_path, 'wb') as f:\n",
    "    pickle.dump(model_details, f)\n",
    "\n",
    "print(\"Model, details, and scaler saved to model_details.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e729bf9a-45fd-44c3-ab34-6c6fbcef51b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': <Sequential name=sequential_4, built=True>, 'scaler': MinMaxScaler(), 'description': 'LSTM model for food price prediction', 'input_shape': (None, 1, 2)}\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import gradio as gr\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the dictionary containing the model and other components\n",
    "model_path = r'D:\\Python\\archive\\model_details.pkl'\n",
    "model_dict = joblib.load(model_path)\n",
    "\n",
    "# Print the contents of the dictionary\n",
    "print(model_dict)\n",
    "\n",
    "# Check if the dictionary contains the required keys\n",
    "if 'model' in model_dict and 'scaler' in model_dict:\n",
    "    # Extract the model and scaler from the dictionary\n",
    "    loaded_model = model_dict['model']\n",
    "    loaded_scaler = model_dict['scaler']\n",
    "else:\n",
    "    print(\"Error: Dictionary does not contain the required keys.\")\n",
    "    exit()\n",
    "\n",
    "# Define dropdown options\n",
    "category_options = [\"oils and fats\", \"cereals and tubers\", \"miscellaneous food\", \"vegetables and fruits\"]\n",
    "commodity_options = [\"Wheat\", \"Rice\", \"Oil (mustard)\", \"Sugar\", \"Potatoes\"]\n",
    "unit_options = [\"KG\", \"L\", \"100 KG\"]\n",
    "price_type_options = [\"Wholesale\", \"Retail\"]\n",
    "\n",
    "\n",
    "# Prediction function\n",
    "def predict(latitude, longitude, category, commodity, unit, pricetype):\n",
    "    try:\n",
    "        # Prepare input data for the model\n",
    "        input_data = {\n",
    "            'latitude': float(latitude),\n",
    "            'longitude': float(longitude),\n",
    "            'category': category_options.index(category),\n",
    "            'commodity': commodity_options.index(commodity),\n",
    "            'unit': unit_options.index(unit),\n",
    "            'pricetype': price_type_options.index(pricetype)\n",
    "        }\n",
    "        input_df = pd.DataFrame([input_data])\n",
    "\n",
    "        # Scale the input data\n",
    "        input_scaled = loaded_scaler.transform(input_df)\n",
    "\n",
    "        # Reshape input to be 3D [samples, timesteps, features]\n",
    "        input_scaled = input_scaled.reshape((input_scaled.shape[0], 1, input_scaled.shape[1]))\n",
    "\n",
    "        # Run the model prediction\n",
    "        predicted_price = loaded_model.predict(input_scaled)\n",
    "        return predicted_price[0][0]\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Create Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=[\n",
    "        gr.Number(label=\"Region (latitude)\"),\n",
    "        gr.Number(label=\"Region (longitude)\"),\n",
    "        gr.Dropdown(label=\"Category\", choices=category_options),\n",
    "        gr.Dropdown(label=\"Commodity\", choices=commodity_options),\n",
    "        gr.Dropdown(label=\"Unit\", choices=unit_options),\n",
    "        gr.Radio(label=\"Price Type\", choices=price_type_options)\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Predicted Price\"),\n",
    "    title=\"Price Prediction of Agri-Horticultural Commodities\",\n",
    "    description=\"Enter the following to get the predicted price.\"\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47455847-365c-4326-a63e-2a03e707b53e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
